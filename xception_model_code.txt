import os
import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
import random
import math
import copy
import cv2

from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from tensorflow.keras.applications.xception import Xception
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback
from tensorflow.keras.callbacks import ReduceLROnPlateau
from tensorflow.keras.applications.xception import preprocess_input, decode_predictions
from tensorflow.keras.optimizers import Adam, RMSprop
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.preprocessing import image_dataset_from_directory
#from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation
from tensorflow.keras.layers import RandomFlip, RandomRotation

from keras import backend as K
from sklearn.metrics import classification_report, confusion_matrix

def seed_everything(seed):
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)

seed_everything(50)

tf. __version__

train_dir = "C:\\Dataset\\Train\\"
test_dir = "C:\\Dataset\\Test\\"
validation_dir ="C:\\Dataset\\Validation\\"

train_data = []

for class_name in os.listdir(train_dir):
    class_path = os.path.join(train_dir, class_name)
    for file_name in os.listdir(class_path):
        file_path = os.path.join(class_path, file_name)
        train_data.append((file_path, class_name))

train_df = pd.DataFrame(train_data, columns=['File_Path', 'Class_Name'])
train_df

train_df['Class_Name'].value_counts().sort_index()

data_augmentation = tf.keras.Sequential([
  tf.keras.layers.RandomFlip("horizontal"),
  tf.keras.layers.RandomRotation(0.2),
  tf.keras.layers.RandomZoom(0.2),
  tf.keras.layers.RandomHeight(0.2),
  tf.keras.layers.RandomWidth(0.2),
])

train_df['File_Path'][0]

category = ['Corn Common Rust','Corn Gray Leaf','Corn Healthy','Corn Northern Leaf Blight','Potato Early Blight','Potato Healthy','Potato Late Blight','Rice Brown Spot','Rice Healthy','Rice Leaf Blast','Rice Neck Blast','Wheat Brown Rust','Wheat Healthy','Wheat Yellow Rust']
count = [1192, 513, 1162, 985,1000, 152, 1000, 613, 1488, 977, 1000, 902, 1116, 924]

crop_df = pd.DataFrame({'Category': ['Corn Common Rust','Corn Gray Leaf','Corn Healthy','Corn Northern Leaf Blight','Potato Early Blight','Potato Healthy','Potato Late Blight','Rice Brown Spot','Rice Healthy','Rice Leaf Blast','Rice Neck Blast','Wheat Brown Rust','Wheat Healthy','Wheat Yellow Rust'],
                   'total_image': [1192, 513, 1162, 985,1000, 152, 1000, 613, 1488, 977, 1000, 902, 1116, 924]})
crop_df.set_index('Category', inplace=True)
crop_df

fig = plt.figure(figsize=(6,6))
ax = plt.subplot(111)
crop_df.total_image.plot(kind='pie', ax=ax, startangle=0, fontsize=10, autopct='%1.1f%%', title='Image Distribution for Class Labels')

plant_df = pd.DataFrame({'Plants': ['Corn','Potato','Rice','Wheat'],
                   'total_image': [3852, 2152, 4078, 2942]})
plant_df.set_index('Plants', inplace=True)
plant_df

fig = plt.figure(figsize=(6,6))
ax = plt.subplot(111)
plant_df.total_image.plot(kind='pie', ax=ax, startangle=0, fontsize=10, autopct='%1.1f%%', title='% per plants')

img_width, img_height = 299, 299

# CORN

EDA_class_names = ['Corn Common Rust', 'Corn Gray Leaf Spot', 'Corn Healthy', 'Corn Northern Leaf Blight']

desired_class = "0"
name = "Common_Rust"

desired_class_df = train_df[train_df['Class_Name'] == desired_class]

num_images_to_plot = 4
    
fig, axes = plt.subplots(1, num_images_to_plot, figsize=(15, 5))

for i, (index, row) in enumerate(desired_class_df.head(num_images_to_plot).iterrows()):
    image_path = row['File_Path']
    image = load_img(image_path, target_size=(img_width, img_height))
    
    axes[i].imshow(image)
    axes[i].set_title(f"Image {i+1}: {name}")
    axes[i].axis('off')

plt.tight_layout()
plt.show()

desired_class = "1"
name = "Corn Gray Leaf Spot"

desired_class_df = train_df[train_df['Class_Name'] == desired_class]

num_images_to_plot = 4
    
fig, axes = plt.subplots(1, num_images_to_plot, figsize=(15, 5))

for i, (index, row) in enumerate(desired_class_df.head(num_images_to_plot).iterrows()):
    image_path = row['File_Path']
    image = load_img(image_path, target_size=(img_width, img_height))
    
    axes[i].imshow(image)
    axes[i].set_title(f"Image {i+1}: {name}")
    axes[i].axis('off')

plt.tight_layout()
plt.show()

desired_class = "2"
name = "Corn Healthy"

desired_class_df = train_df[train_df['Class_Name'] == desired_class]

num_images_to_plot = 4
    
fig, axes = plt.subplots(1, num_images_to_plot, figsize=(15, 5))

for i, (index, row) in enumerate(desired_class_df.head(num_images_to_plot).iterrows()):
    image_path = row['File_Path']
    image = load_img(image_path, target_size=(img_width, img_height))
    
    axes[i].imshow(image)
    axes[i].set_title(f"Image {i+1}: {name}")
    axes[i].axis('off')

plt.tight_layout()
plt.show()

desired_class = "3"
name = "Corn Northern Leaf Blight"

desired_class_df = train_df[train_df['Class_Name'] == desired_class]

num_images_to_plot = 4
    
fig, axes = plt.subplots(1, num_images_to_plot, figsize=(15, 5))

for i, (index, row) in enumerate(desired_class_df.head(num_images_to_plot).iterrows()):
    image_path = row['File_Path']
    image = load_img(image_path, target_size=(img_width, img_height))
    
    axes[i].imshow(image)
    axes[i].set_title(f"Image {i+1}: {name}")
    axes[i].axis('off')

plt.tight_layout()
plt.show()

# MODEL

opt = tf.keras.optimizers.Adam(learning_rate=1e-4)
loss = 'categorical_crossentropy'
metrics = ['accuracy']

batch_size = 32

# Xception - MODEL

model1 = Xception(include_top=False,input_shape=(299, 299, 3), weights='imagenet')

input_shape= (299, 299)

datagen_train = ImageDataGenerator(rescale=1./255,
                                  width_shift_range=0.2,
                                  height_shift_range=0.2,
                                  zoom_range=0.2,
                                  horizontal_flip=True,
                                  vertical_flip=False)


datagen_test = ImageDataGenerator(rescale=1./255)
datagen_val = ImageDataGenerator(rescale=1./255)


generator_train = datagen_train.flow_from_directory(directory=train_dir,
                                                    target_size=input_shape,
                                                    batch_size=batch_size,
                                                    shuffle=True)

generator_test = datagen_test.flow_from_directory(directory=test_dir,
                                                  target_size=input_shape,
                                                  batch_size=batch_size,
                                                  shuffle=False)

generator_val = datagen_val.flow_from_directory(directory=validation_dir,
                                                  target_size=input_shape,
                                                  batch_size=batch_size,
                                                  shuffle=False)

math.ceil(generator_train.samples)

next(generator_train)[1]

conv_model = Model(inputs=model1.input, outputs=model1.output)

new_model = Sequential()
new_model.add(conv_model)
new_model.add(Flatten())
new_model.add(Dropout(0.5))
new_model.add(Dense(512, activation='relu'))
new_model.add(Dense(14, activation='softmax'))

new_model.compile(optimizer= opt, loss=loss, metrics=metrics)

num_iters = 30000
num_batches_train = generator_train.n // batch_size

# epochs = int(num_iters / num_batches_train)
epochs = 11
print("Epoch: ",epochs)
desired_train_accuracy = 0.99

steps_per_epoch = generator_train.n // batch_size
steps_val = generator_val.n // batch_size
print("Steps_per_epoch: ",steps_per_epoch)
print("Steps_val: ",steps_val)

Checkpoint = ModelCheckpoint("Xception.h5", monitor="val_accuracy", save_best_only=True, mode="max")
EarlyStop = EarlyStopping(monitor="accuracy", baseline=desired_train_accuracy, patience=10, restore_best_weights=True, mode="auto")

history = new_model.fit(generator_train,
                                  epochs=epochs,
                                  callbacks=[Checkpoint, EarlyStop],
                                  steps_per_epoch=steps_per_epoch,
                                  validation_data=generator_val,
                                  validation_steps=steps_val)

model_path = "Xception.h5"

new_model=tf.keras.models.load_model(model_path)

Y_pred = new_model.predict(generator_test)
y_pred = np.argmax(Y_pred, axis=1)

class_labels = list(generator_test.class_indices.keys())

print(classification_report(generator_test.classes, y_pred, target_names=class_labels))

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(history.history["loss"], label="train_loss")
plt.plot(history.history["val_loss"], label="val_loss")
plt.legend()
plt.title("Loss")

plt.subplot(1, 2, 2)
plt.plot(history.history["accuracy"], label="train_accuracy")
plt.plot(history.history["val_accuracy"], label="val_accuracy")
plt.legend()
plt.title("Accuracy")

plt.show()

cm = confusion_matrix(generator_test.classes, y_pred)

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel("Predicted Class")
plt.ylabel("True Class")
plt.title("Confusion Matrix")
plt.show()

image_path_show_X=[]
image_show_X=[]

class_image_path_show_X=[]
class_image_show_X=[]

# MISCLASSIFY IMAGES

img_width, img_height= 299, 299
misclassified_images_X = []
for i in range(len(y_pred)):
    if y_pred[i] != generator_test.classes[i]:
        img_path = generator_test.filepaths[i]
        true_label = generator_test.classes[i]
        predicted_label = y_pred[i]
        misclassified_images_X.append((img_path, true_label, predicted_label))


num_display = 3
for img_path, true_label, predicted_label in misclassified_images_X[:num_display]:
    img = load_img(img_path, target_size=(img_width, img_height))
    plt.imshow(img)
    plt.title(f"True: {class_labels[true_label]}, Predicted: {class_labels[predicted_label]}")
    plt.axis('off')
    plt.show()
    
    image_path_show_X.append(img_path)
    image_show_X.append(img)

# CORRECTLY CLASSIFY IMAGES

img_width, img_height= 299, 299
classified_images_X = []
for i in range(len(y_pred)):
    if y_pred[i] == generator_test.classes[i]:
        img_path = generator_test.filepaths[i]
        true_label = generator_test.classes[i]
        predicted_label = y_pred[i]
        classified_images_X.append((img_path, true_label, predicted_label))


num_display = 3
for img_path, true_label, predicted_label in classified_images_X[:num_display]:
    img = load_img(img_path, target_size=(img_width, img_height))
    plt.imshow(img)
    plt.title(f"True: {class_labels[true_label]}, Predicted: {class_labels[predicted_label]}")
    plt.axis('off')
    plt.show()
    
    class_image_path_show_X.append(img_path)
    class_image_show_X.append(img)

image_path_show_X
image_show_X